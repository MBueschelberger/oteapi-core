{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1e4e545-8807-49e8-8def-92792a719c00",
   "metadata": {},
   "source": [
    "# OTE-API\n",
    "\n",
    "*Connect anything - build a processing pipeline - run from anywhere!*\n",
    "\n",
    "The Ontology-based Translation Environment Application Programming Interface is\n",
    "a framework for connecting heterogenous data resources, semantic interoperability frameworks, open simulation platforms and standalone simulation tools. The OTE-API allows for building complex use-case representations by combining a set of simple reusable functions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12182e90-4bdf-47b3-81ff-764c70a3e2d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b8d5f02f-c659-4f31-8d70-dd2d39bbb963",
   "metadata": {},
   "source": [
    "![./oteapi-Strategies.drawio.png](./oteapi-Strategies.drawio.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a383aa08-143d-4608-a884-648a64231ed9",
   "metadata": {},
   "source": [
    "The OTEAPI provides a unified way to manage complex software\n",
    "processing. By combining reusable elements for accessing or\n",
    "downloading data, parsing information, transforming information and\n",
    "performing business logic, the OTEAPI is highly adoptable to different\n",
    "business cases.\n",
    "\n",
    "OTEAPI is an implementation of the pipe and filter architectural\n",
    "pattern. This simply describes a set of connected components that\n",
    "process a stream of data from an input source to a reciever such as a\n",
    "data sink. Once a pipeline is constructed, it is possible to execute\n",
    "data processing as if it were a single component. The pipeline(s) can\n",
    "furher be embedded in a larger workflow system.\n",
    "\n",
    "A complex processing scenario is defined by constructing a\n",
    "\"pipeline\" from reusable and interchangable parts. OTEAPI supports 6\n",
    "main categories of tasks:\n",
    "\n",
    "* Data access\n",
    "* Data filtering (Data subset extraction)\n",
    "* Syntactic analysis (Parsing)\n",
    "* Ontological mapping (Semantic Data Modelling)\n",
    "* Synchronous Information Processing (Functions)\n",
    "* Asynchronous Processing (Transformations running in the background)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2bacfd8-0b37-44a4-9a37-83674ab6acf6",
   "metadata": {},
   "source": [
    "## Data access (Information Retrieval)\n",
    "\n",
    "Accessing data will typically involve authorization, transportation\n",
    "protocols and query languages. A simple data access module will be\n",
    "able to initiate a transport protocol (for instance http) and access\n",
    "an artifact given a unique URL.\n",
    "\n",
    "## Data Filtering\n",
    "\n",
    "Data filtering allows for extracting a subset of the available data,\n",
    "by defining a view or a size limitation. The data filter is usually\n",
    "very closesly related with the data accessor, and may include data\n",
    "source specific query languages.\n",
    "\n",
    "## Syntactic Analysis\n",
    "\n",
    "Heterogenous datasources have different syntactic ways of defining the\n",
    "structure and contents. Some datasource will provide schemas and\n",
    "metadata (SQL, HDF5), some are documented fileformats (CSV, XLSX,\n",
    "++). In order to manage the rich variety of formats, a parser or\n",
    "syntactic analyser is needed for further processing of the data.\n",
    "\n",
    "## Semantic Mapping\n",
    "\n",
    "A data stream associated with a semantic datamodel allows for semantic\n",
    "interoperability in the sense that the data can be correctly\n",
    "interpreted from a common language or domain definition (ontology).\n",
    "\n",
    "Training of a machine learning model is a practical example where\n",
    "semantic mapping becomes very useful. The machine learning software is\n",
    "agnostic to the meaning of the training data, however the datamodel\n",
    "representing the input data can be dynamically mapped to appropriate\n",
    "concepts. \n",
    "\n",
    "\n",
    "## Synchronous Information Processing\n",
    "\n",
    "OTEAPI defines two different methods of generating new information\n",
    "from a stream of data. With synchrounous information processing an\n",
    "operation or *function* will be performed and completed the next\n",
    "step in the pipeline is called. This task is very generic, and \n",
    "supports a wide range of different types of operations from performing\n",
    "operations on the data to serializing data.\n",
    "\n",
    "## Asynchronous Processing\n",
    "\n",
    "Asynchronous processing differs from the synchronous processing in that \n",
    "it will start a background task and not wait for it to finish. Asynchronous \n",
    "processing is useful for instance when starting long-running computations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a9d99b0-ba67-4214-8045-0f0b1ede2268",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Pipe and Filter\n",
    "\n",
    "![./context-filter-session-interaction.png](./context-filter-session-interaction.png)\n",
    "\n",
    "The context-filter-session interaction diagrams illustrates the communication between a context class, a filter and the session. The session is simply an in-memory key-value storage that is used as temporal memory management in the communication between different filter types. The session data will first be fetched into the context class as sent as argument to the filter initialize method. Note that initialize is a pure function as the filter strategy is stateless, and the only purpose of the initialize method is to create an object that will be added or updated in the current session. \n",
    "\n",
    "In a composition that includes several pipes and filter connections, the initialize() method will be sequencially called going upstream from the last filter in the pipeline to the first. This allows the last filter to send a message to the first filters (via the session). This is needed when constraints cannot be determined at configuration time. See Filter Composision Interaction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da31582-f7b3-410c-9155-015d76dc6e04",
   "metadata": {},
   "source": [
    "# Filter Composision Interaction\n",
    "![./pipe-and-filter-connection.png](./pipe-and-filter-connection.png)\n",
    "\n",
    "\n",
    "dsds\n",
    "\n",
    "![./pipe-filter-interaction.drawio.png](./pipe-filter-interaction.drawio.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e0cde5-72d7-448e-bd9e-c0919ae6f091",
   "metadata": {},
   "source": [
    "# High Level Overview - Execution order\n",
    "\n",
    "When a pipeline is composed of a set of *pipes* and *filters*, the pipeline can be executed as if it was a simple component. By calling the .get() method on the pipeline, a sequence of operations on the different strategies are executed.\n",
    "\n",
    "![./pipeline.png](./pipeline.png)\n",
    "A pipeline composed of 3 filters (FilterA, FilterB and FilterC) and two pipes\n",
    "\n",
    "![./pipeline-get.png](./pipeline-get.png)\n",
    "\n",
    "## Execution order\n",
    "\n",
    "![./execution-order.png](./execution-order.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a704367e-345f-49a5-a7a9-d694a44f2bec",
   "metadata": {},
   "source": [
    "## Strategies everywhere!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378b1887-0912-4b25-aaf6-67b0f911f196",
   "metadata": {},
   "source": [
    "A simplification of common materials modelling use cases is as following: data is read from a data source, filtered and converted into a suitable representation, and used as input in a simulation. Output from the simulation is used in analysis or post-processed for further simulation. One pattern that emerge is that we have a stream of data, and a successive steps of transformations on the data. This allows us to generalize the use-cases into the following:\n",
    "\n",
    "data source --(pipe)--> filter --(pipe)--> filter --(pipe)--> data target\n",
    "\n",
    "A pipe is simply a source that consumes data by an input *filter*.\n",
    "A \"filter\" can be any transformation of the data or operations that receives the stream of data from an input pipe, and delivers data as a stream to an output pipe. There can be many different types of filters, but in general they will share the same generic interfaces, and can in principle be connected to any pipe.\n",
    "\n",
    "Key advantages to the pipe & filter patterns is that it allows for loose and flexible coupling of interchangable filters, the filters are re-usable, a set of pipelines can be run parallel. Another important factor is that filters can be \"anything\" as long as it honours the interface specification, and is treated as \"black-boxes\" by the system.\n",
    "\n",
    "A common design pattern for managing a set of (run-time) interchangable modules with different implementations is the *strategy pattern*. A module will run the same *named* function, but the instanse of the object that is called will changed dependent on the context. \n",
    "\n",
    "In the score of the Ontology based Translation Environment there are four main categories of operations. \n",
    "    * Resource operations administrates data sources and target sources. This includes downloading data using various protocols, parsing specific file formats, interacting with web services or database management systems, generating target data and uploading information\n",
    "    * Mapping between source specific metadata and general or domain specific semantic representations\n",
    "    * Defining filtering operations that specifies a subset of information\n",
    "    * Transformations that operates on data and produce new information\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22a8d5e-1ae5-439c-b79d-8bf75bbc9143",
   "metadata": {},
   "source": [
    "## Pipeline execution order\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c75edf-c0cb-47c4-91de-a855285d1c50",
   "metadata": {},
   "source": [
    "### Resource operations\n",
    "\n",
    "| Property    | Type   | Description                                                                  |\n",
    "|-------------|--------|------------------------------------------------------------------------------|\n",
    "| downloadUrl | string | Definition: The URL of the downloadable file in a given format. E.g. CSV file or RDF file. Usage: `downloadURL` *SHOULD* be used for the URL at which this distribution is available directly, typically through a HTTPS GET request or SFTP. |\n",
    "| mediaType | string | The media type of the distribution as defined by IANA [[IANA-MEDIA-TYPES](https://www.w3.org/TR/vocab-dcat-2/#bib-iana-media-types)]. Usage: This property *SHOULD* be used when the media type of the distribution is defined in IANA [[IANA-MEDIA-TYPES](https://www.w3.org/TR/vocab-dcat-2/#bib-iana-media-types)]. |\n",
    "| accessUrl | string | A URL of the resource that gives access to a distribution of the dataset. E.g. landing page, feed, SPARQL endpoint. Usage: `accessURL` *SHOULD* be used for the URL of a service or location that can provide access to this distribution, typically through a Web form, query or API call. `downloadURL` is preferred for direct links to downloadable resources. |\n",
    "| accessService | string | A data service that gives access to the distribution of the dataset. |\n",
    "| license | string | A legal document under which the distribution is made available. |\n",
    "| accessRights | string | A rights statement that concerns how the distribution is accessed. |\n",
    "| description | string | A free-text account of the distribution. |\n",
    "| publisher | string | The entity responsible for making the resource/item available. |\n",
    "| configuration | | Resource-specific configuration options given as key/value-pairs. |\n",
    "\n",
    "\n",
    "The configuration can include a reference to the DataCache. The DataCache is an internal storage mechanism that allows for temporarily storing artifacts for an active period to avoid the need to accessing the same resource multiple times over the network.\n",
    "\n",
    "| Property    | Type   | Description                                                                  |\n",
    "|-------------|--------|------------------------------------------------------------------------------|\n",
    "| cacheDir | string | Cache directory. |\n",
    "| accessKey | string | Key with which the downloaded content can be accessed. Should preferable be the hash (corresponding to `hashType`) of the content if it is known. |\n",
    "| hashType | string | Hash algorithm to use for creating hash keys for stored data. Can be any algorithm supported by hashlib. |\n",
    "| expireTime | integer | Number of seconds before the cache entry expires. Zero means no expiration. Default is two weeks. |\n",
    "| tag | string | Tag assigned to the downloaded content, typically identifying a session. Used with the `evict()` method to clean up a all cache entries with a given tag. |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d72886f-ebac-4b90-ac5a-90dcc41b36cd",
   "metadata": {},
   "source": [
    "### Mapping operations\n",
    "\n",
    "| Property    | Type   | Description                                                                  |\n",
    "|-------------|--------|------------------------------------------------------------------------------|\n",
    "| mappingType | string | Type of registered mapping strategy. E.g., `mapping/demo`. |\n",
    "| prefixes | object | List of shortnames that expands to an IRI given as local value/IRI-expansion-pairs. |\n",
    "| triples | array | List of semantic triples given as (subject, predicate, object). |\n",
    "| configuration | object | Mapping-specific configuration options given as key/value-pairs. |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf7256fc-8d7d-4f9e-b572-487d138612a2",
   "metadata": {},
   "source": [
    "### filtering operations\n",
    "\n",
    "| Property    | Type   | Description                                                                  |\n",
    "|-------------|--------|------------------------------------------------------------------------------|\n",
    "| filterType | string | Type of registered filter strategy. E.g., `filter/sql`. |\n",
    "| query | string | Define a query operation. |\n",
    "| condition | string | Logical statement indicating when a filter should be applied. |\n",
    "| limit | integer | Number of items remaining after a filter expression. |\n",
    "| configuration | object | Filter-specific configuration options given as key/value-pairs. |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab98bad5-8d29-4fa8-9f95-8b90de3a4e66",
   "metadata": {},
   "source": [
    "### Transformations\n",
    "\n",
    "| Property    | Type   | Description                                                                  |\n",
    "|-------------|--------|------------------------------------------------------------------------------|\n",
    "| transformation_type | string | Type of registered transformation strategy. E.g., `celery/remote`. |\n",
    "| name | string | Human-readable name of the transformation strategy. |\n",
    "| description | string | A free-text account of the transformation. |\n",
    "| due | string | Optional field to indicate a due data/time for when a transformation should finish. |\n",
    "| priority |  | Define the process priority of the transformation execution. |\n",
    "| secret | string | Authorization secret given when running a transformation. |\n",
    "| configuration | object | Transformation-specific configuration options given as key/value-pairs. |\n",
    "\n",
    "\n",
    "#### Transformation status\n",
    "\n",
    "| Property    | Type   | Description                                                                  |\n",
    "|-------------|--------|------------------------------------------------------------------------------|\n",
    "| id | string | ID for the given transformation process. |\n",
    "| status | string | Status for the transformation process. |\n",
    "| messages | array | Messages related to the transformation process. |\n",
    "| created | string | Time of creation for the transformation process. Given in UTC. |\n",
    "| startTime | string | Time when the transformation process started. Given in UTC. |\n",
    "| finishTime | string | Time when the tranformation process finished. Given in UTC. |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d83fcdec-4d6e-4dcd-b80e-835bc76be4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Dict, Optional, Union, List\n",
    "from pathlib import Path\n",
    "from pydantic import AnyUrl, BaseModel, Field, root_validator, conlist\n",
    "from datetime import datetime\n",
    "from enum import Enum\n",
    "from typing import Dict, List, Optional\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "SemanticTriple = conlist(str, min_items=3, max_items=3)\n",
    "\n",
    "class FilterConfig(BaseModel):\n",
    "    \"\"\"Filter Strategy Data Configuration.\"\"\"\n",
    "\n",
    "    filterType: str = Field(\n",
    "        ..., description=\"Type of registered filter strategy. E.g., `filter/sql`.\"\n",
    "    )\n",
    "    query: Optional[str] = Field(None, description=\"Define a query operation.\")\n",
    "    condition: Optional[str] = Field(\n",
    "        None,\n",
    "        description=\"Logical statement indicating when a filter should be applied.\",\n",
    "    )\n",
    "    limit: Optional[int] = Field(\n",
    "        None, description=\"Number of items remaining after a filter expression.\"\n",
    "    )\n",
    "    configuration: Optional[Dict] = Field(\n",
    "        None,\n",
    "        description=\"Filter-specific configuration options given as key/value-pairs.\",\n",
    "    )\n",
    "\n",
    "class MappingConfig(BaseModel):\n",
    "    \"\"\"Mapping Strategy Data Configuration.\"\"\"\n",
    "\n",
    "    mappingType: str = Field(\n",
    "        ..., description=\"Type of registered mapping strategy. E.g., `mapping/demo`.\"\n",
    "    )\n",
    "    prefixes: Optional[Dict[str, str]] = Field(\n",
    "        None,\n",
    "        description=(\n",
    "            \"List of shortnames that expands to an IRI \"\n",
    "            \"given as local value/IRI-expansion-pairs.\"\n",
    "        ),\n",
    "    )\n",
    "    triples: Optional[List[SemanticTriple]] = Field(  # type: ignore[valid-type]\n",
    "        None,\n",
    "        description=\"List of semantic triples given as (subject, predicate, object).\",\n",
    "    )\n",
    "    configuration: Optional[Dict] = Field(\n",
    "        None,\n",
    "        description=\"Mapping-specific configuration options given as key/value-pairs.\",\n",
    "    )\n",
    "    \n",
    "class DataCacheConfig(BaseModel):\n",
    "    \"\"\"DataCache Configuration.\"\"\"\n",
    "\n",
    "    cacheDir: Path = Field(\"oteapi\", description=\"Cache directory.\")\n",
    "    accessKey: str = Field(\n",
    "        None,\n",
    "        description=\"Key with which the downloaded content can be accessed. \"\n",
    "        \"Should preferable be the hash (corresponding to `hashType`) of the \"\n",
    "        \"content if it is known.\",\n",
    "    )\n",
    "    hashType: str = Field(\n",
    "        \"md5\",\n",
    "        description=\"Hash algorithm to use for creating hash keys for stored \"\n",
    "        \"data. Can be any algorithm supported by hashlib.\",\n",
    "    )\n",
    "    expireTime: int = Field(\n",
    "        3600 * 24 * 14,\n",
    "        description=\"Number of seconds before the cache entry expires. \"\n",
    "        \"Zero means no expiration. Default is two weeks.\",\n",
    "    )\n",
    "    tag: str = Field(\n",
    "        None,\n",
    "        description=\"Tag assigned to the downloaded content, typically \"\n",
    "        \"identifying a session. Used with the `evict()` method to clean up a \"\n",
    "        \"all cache entries with a given tag.\",\n",
    "    )\n",
    "\n",
    "class ResourceConfig(BaseModel):\n",
    "    \"\"\"Resource Strategy Data Configuration.\n",
    "    Important:\n",
    "        Either of the pairs of attributes `downloadUrl`/`mediaType` or\n",
    "        `accessUrl`/`accessService` MUST be specified.\n",
    "    \"\"\"\n",
    "\n",
    "    downloadUrl: Optional[AnyUrl] = Field(\n",
    "        None,\n",
    "        description=(\n",
    "            \"Definition: The URL of the downloadable file in a given format. E.g. CSV \"\n",
    "            \"file or RDF file.\\n\\nUsage: `downloadURL` *SHOULD* be used for the URL at\"\n",
    "            \" which this distribution is available directly, typically through a HTTPS\"\n",
    "            \" GET request or SFTP.\"\n",
    "        ),\n",
    "    )\n",
    "    mediaType: Optional[str] = Field(\n",
    "        None,\n",
    "        description=(\n",
    "            \"The media type of the distribution as defined by IANA \"\n",
    "            \"[[IANA-MEDIA-TYPES](https://www.w3.org/TR/vocab-dcat-2/#bib-iana-media-types)]\"\n",
    "            \".\\n\\nUsage: This property *SHOULD* be used when the media\"\n",
    "            \" type of the distribution is defined in IANA \"\n",
    "            \"[[IANA-MEDIA-TYPES](https://www.w3.org/TR/vocab-dcat-2/#bib-iana-media-types)].\"\n",
    "        ),\n",
    "    )\n",
    "    accessUrl: Optional[AnyUrl] = Field(\n",
    "        None,\n",
    "        description=(\n",
    "            \"A URL of the resource that gives access to a distribution of \"\n",
    "            \"the dataset. E.g. landing page, feed, SPARQL endpoint.\\n\\nUsage: \"\n",
    "            \"`accessURL` *SHOULD* be used for the URL of a service or location that \"\n",
    "            \"can provide access to this distribution, typically through a Web form, \"\n",
    "            \"query or API call.\\n`downloadURL` is preferred for direct links to \"\n",
    "            \"downloadable resources.\"\n",
    "        ),\n",
    "    )\n",
    "    accessService: Optional[str] = Field(\n",
    "        None,\n",
    "        description=(\n",
    "            \"A data service that gives access to the distribution of the dataset.\"\n",
    "        ),\n",
    "    )\n",
    "    license: Optional[str] = Field(\n",
    "        None,\n",
    "        description=(\n",
    "            \"A legal document under which the distribution is made available.\"\n",
    "        ),\n",
    "    )\n",
    "    accessRights: Optional[str] = Field(\n",
    "        None,\n",
    "        description=(\n",
    "            \"A rights statement that concerns how the distribution is accessed.\"\n",
    "        ),\n",
    "    )\n",
    "    description: Optional[str] = Field(\n",
    "        None, description=\"A free-text account of the distribution.\"\n",
    "    )\n",
    "    publisher: Optional[str] = Field(\n",
    "        None,\n",
    "        description=\"The entity responsible for making the resource/item available.\",\n",
    "    )\n",
    "    configuration: Union[DataCacheConfig, Dict[str, Any]] = Field(\n",
    "        {},\n",
    "        description=\"Resource-specific configuration options given as key/value-pairs.\",\n",
    "    )\n",
    "    \n",
    "class PriorityEnum(str, Enum):\n",
    "    \"\"\"Defining process priority enumerators.\n",
    "    Process priorities:\n",
    "    - Low\n",
    "    - Medium\n",
    "    - High\n",
    "    \"\"\"\n",
    "\n",
    "    LOW = \"Low\"\n",
    "    MEDIUM = \"Medium\"\n",
    "    HIGH = \"High\"\n",
    "\n",
    "\n",
    "class TransformationConfig(BaseModel):\n",
    "    \"\"\"Transformation Strategy Data Configuration.\"\"\"\n",
    "\n",
    "    transformation_type: str = Field(\n",
    "        ...,\n",
    "        description=(\n",
    "            \"Type of registered transformation strategy. E.g., `celery/remote`.\"\n",
    "        ),\n",
    "    )\n",
    "    name: Optional[str] = Field(\n",
    "        None, description=\"Human-readable name of the transformation strategy.\"\n",
    "    )\n",
    "    description: Optional[str] = Field(\n",
    "        None, description=\"A free-text account of the transformation.\"\n",
    "    )\n",
    "    due: Optional[datetime] = Field(\n",
    "        None,\n",
    "        description=(\n",
    "            \"Optional field to indicate a due data/time for when a transformation \"\n",
    "            \"should finish.\"\n",
    "        ),\n",
    "    )\n",
    "    priority: Optional[PriorityEnum] = Field(\n",
    "        PriorityEnum.MEDIUM,\n",
    "        description=\"Define the process priority of the transformation execution.\",\n",
    "    )\n",
    "    secret: Optional[str] = Field(\n",
    "        None,\n",
    "        description=\"Authorization secret given when running a transformation.\",\n",
    "    )\n",
    "    configuration: Optional[Dict] = Field(\n",
    "        None,\n",
    "        description=(\n",
    "            \"Transformation-specific configuration options given as key/value-pairs.\"\n",
    "        ),\n",
    "    )\n",
    "\n",
    "\n",
    "class TransformationStatus(BaseModel):\n",
    "    \"\"\"Return from transformation status.\"\"\"\n",
    "\n",
    "    id: str = Field(..., description=\"ID for the given transformation process.\")\n",
    "    status: Optional[str] = Field(\n",
    "        None, description=\"Status for the transformation process.\"\n",
    "    )\n",
    "    messages: Optional[List[str]] = Field(\n",
    "        None, description=\"Messages related to the transformation process.\"\n",
    "    )\n",
    "    created: Optional[datetime] = Field(\n",
    "        None,\n",
    "        description=\"Time of creation for the transformation process. Given in UTC.\",\n",
    "    )\n",
    "    startTime: Optional[datetime] = Field(\n",
    "        None, description=\"Time when the transformation process started. Given in UTC.\"\n",
    "    )\n",
    "    finishTime: Optional[datetime] = Field(\n",
    "        None, description=\"Time when the tranformation process finished. Given in UTC.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "659c9bc6-aab7-453c-8c68-4173829381f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Property    | Type   | Description                                                                  |\n",
      "|-------------|--------|------------------------------------------------------------------------------|\n",
      "| id | string | ID for the given transformation process. |\n",
      "| status | string | Status for the transformation process. |\n",
      "| messages | array | Messages related to the transformation process. |\n",
      "| created | string | Time of creation for the transformation process. Given in UTC. |\n",
      "| startTime | string | Time when the transformation process started. Given in UTC. |\n",
      "| finishTime | string | Time when the tranformation process finished. Given in UTC. |\n"
     ]
    }
   ],
   "source": [
    "properties = TransformationStatus.schema()['properties']\n",
    "head=(\n",
    "    \"| Property    | Type   | Description                                                                  |\\n\"\n",
    "    \"|-------------|--------|------------------------------------------------------------------------------|\"\n",
    "    )\n",
    "print (head)\n",
    "for prop in properties:\n",
    "    typ = '' if not 'type' in properties[prop] else properties[prop]['type']\n",
    "    print ('|', prop, '|', typ, '|', properties[prop]['description'].strip(), '|')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd09571-89f5-43a8-960d-fa585ed25862",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
